{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk0QuspHeadV"
      },
      "source": [
        "In this case we will try to run more epochs in this model hoping that we could get a better result using this model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration of the variables notebook\n",
        "model_name = 'roberta-base' #@param\n",
        "value_batch_size =16 #@param\n",
        "value_learning_rate = 2.057626963810742e-06 #@param\n",
        "value_warmup = 0.2410014240231825 #@param\n",
        "value_w_decay = 8.747541196471078e-09 #@param\n",
        "value_n_epochs = 4  #@param\n",
        "value_dropout = 0.3789390401864389 #@param\n",
        "value_n_labels = 6 #@param\n",
        "\n",
        "config_models ={\n",
        "    \"model_name\": model_name,\n",
        "    \"n_labels\": value_n_labels,\n",
        "    \"batch_size\": value_batch_size,\n",
        "    \"lr\": value_learning_rate,\n",
        "    \"warmup\": value_warmup,\n",
        "    \"train_size\": None,\n",
        "    \"w_decay\": value_w_decay,\n",
        "    \"n_epochs\": value_n_epochs,\n",
        "    \"dropout_vals\": value_dropout\n",
        "}"
      ],
      "metadata": {
        "id": "9cYKpA9ef3js"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XR0R4-BeRNZ"
      },
      "source": [
        "# Preparation for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "W4kVtaRwo78h"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pytorch_lightning bertviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "dvLOfLRZpgRH",
        "outputId": "6242cab6-c938-413c-fdd6-6cb08b64e18f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of available CPU cores: 8\n",
            "Setting num_workers to: 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.21176470588235294, 0.807843137254902, 0.5411764705882353),\n",
              " (0.4549019607843137, 0.21176470588235294, 0.9607843137254902),\n",
              " (0.21568627450980393, 0.21176470588235294, 0.9568627450980393),\n",
              " (0.21176470588235294, 0.6823529411764706, 0.9607843137254902),\n",
              " (0.7019607843137254, 0.21176470588235294, 0.9607843137254902),\n",
              " (0.9725490196078431, 0.08627450980392157, 0.3686274509803922),\n",
              " (0.21176470588235294, 0.4392156862745098, 0.6039215686274509),\n",
              " (0.21176470588235294, 0.4470588235294118, 0.9607843137254902),\n",
              " (0.47843137254901963, 0.807843137254902, 0.36470588235294116)]"
            ],
            "text/html": [
              "<svg  width=\"495\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#36ce8a;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#7436f5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#3736f4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#36aef5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#b336f5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#f8165e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#36709a;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#3672f5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#7ace5d;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#@title Importing the modules\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "enable_code_paths = True\n",
        "enable_block = False\n",
        "\n",
        "if enable_code_paths:\n",
        "    URL_path = \"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/dataset/clean_dataset.csv\"\n",
        "    URL_synthetic_data = \"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/dataset/synthetic_data.csv\"\n",
        "    URL_path_save = \"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/model\"\n",
        "    URL_helper =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/helper/\"\n",
        "    URL_hyperparameters =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/hyperparameters/\"\n",
        "    URL_test_labels =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/dataset/test_labels.csv\"\n",
        "    URL_test =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/dataset/test.csv\"\n",
        "    URL_model_saved_015 =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/model/015_model\"\n",
        "    URL_model_saved_017 =\"/content/drive/MyDrive/Code/Data_science_Turing_college/Colabs/14_002_NLP/model/017_model\"\n",
        "else :\n",
        "    URL_path = \"/content/drive/MyDrive/turing_college_experiments/14_NLP/helper\"\n",
        "    URL_path_save = \"/content/drive/MyDrive/turing_college_experiments/14_NLP/model\"\n",
        "    URL_helper = \"/content/drive/MyDrive/turing_college_experiments/14_NLP/helper\"\n",
        "import sys\n",
        "sys.path.append(URL_helper)\n",
        "\n",
        "from colab_helper import proportion_balance_classes\n",
        "\n",
        "\"\"\"\n",
        "Verify the cores and gpu in the colab\n",
        "\"\"\"\n",
        "num_cores = os.cpu_count()  # Get the number of CPU cores\n",
        "print(f'Number of available CPU cores: {num_cores}')\n",
        "num_workers_colab = num_cores - 1\n",
        "print(f'Setting num_workers to: {num_workers_colab}')\n",
        "\n",
        "num_gpus_colab = torch.cuda.device_count()\n",
        "gpu_list = [torch.cuda.get_device_name(i) for i in range(num_gpus_colab)]\n",
        "num_gpus_colab, gpu_list\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "import the modules and configuration colors\n",
        "\"\"\"\n",
        "## Core Libraries\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sklearn for Evaluation Metrics and Model Selection\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, recall_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# PyTorch Libraries and Lightning\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Hugging Face Transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel,\n",
        "    get_linear_schedule_with_warmup, utils\n",
        ")\n",
        "\n",
        "# Visualization Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import seaborn as sns\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from bertviz import model_view\n",
        "\n",
        "# Progress Bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "import joblib\n",
        "\n",
        "# Google Colab (if applicable)\n",
        "from google.colab import drive\n",
        "\n",
        "# TorchMetrics (for AUROC calculation)\n",
        "from torchmetrics.functional.classification import auroc\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# Suppress standard warnings\n",
        "utils.logging.set_verbosity_error()\n",
        "\n",
        "\"\"\"\n",
        "Colorama\n",
        "\"\"\"\n",
        "custom_colors = ['#36CE8A', \"#7436F5\",\"#3736F4\",   \"#36AEF5\", \"#B336F5\", \"#f8165e\", \"#36709A\",  \"#3672F5\", \"#7ACE5D\"]\n",
        "gradient_colors = [ \"#36CE8A\", '#7436F5']\n",
        "color_palette_custom  = sns.set_palette(custom_colors)\n",
        "theme_color = sns.color_palette(color_palette_custom, 9)\n",
        "cmap_theme = LinearSegmentedColormap.from_list('custom_colormap', gradient_colors)\n",
        "theme_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHsefh5QojqZ"
      },
      "source": [
        "We will be exploring the Roberta model and see if we could find any good performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "Cj6N-JVvmmN_",
        "outputId": "fa03e6cc-df8e-4574-c224-2abd08ec17b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        comment_text  toxic  severe_toxic  \\\n",
            "0  ExplanationWhy the edits made under my usernam...      0             0   \n",
            "1  D'aww! He matches this background colour I'm s...      0             0   \n",
            "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
            "3  \"MoreI can't make any real suggestions on impr...      0             0   \n",
            "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
            "\n",
            "   obscene  threat  insult  identity_hate  \n",
            "0        0       0       0              0  \n",
            "1        0       0       0              0  \n",
            "2        0       0       0              0  \n",
            "3        0       0       0              0  \n",
            "4        0       0       0              0  \n",
            "(63978, 7)\n",
            "dataframe_test\n",
            "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
            "51138      1             0        0       0       0              0   \n",
            "40102      0             0        0       0       0              0   \n",
            "144        0             0        0       0       0              0   \n",
            "34995      0             0        0       0       0              0   \n",
            "26869      0             0        0       0       0              0   \n",
            "\n",
            "                                            comment_text  \n",
            "51138  \" \\n\\n == Alleged Original Research == \\n\\n I ...  \n",
            "40102  Вспоминая...== \\n\\n Хороший, годный мультик. Ж...  \n",
            "144    == Anthony Browne in Political Correctness == ...  \n",
            "34995  \"And I see you frequently calling on \"\"broadly...  \n",
            "26869  I have no idea what that has to do with the to...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        comment_text  toxic  severe_toxic  \\\n",
              "0  ExplanationWhy the edits made under my usernam...      0             0   \n",
              "1  D'aww! He matches this background colour I'm s...      0             0   \n",
              "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
              "3  \"MoreI can't make any real suggestions on impr...      0             0   \n",
              "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
              "\n",
              "   obscene  threat  insult  identity_hate  non_toxic  \n",
              "0        0       0       0              0          1  \n",
              "1        0       0       0              0          1  \n",
              "2        0       0       0              0          1  \n",
              "3        0       0       0              0          1  \n",
              "4        0       0       0              0          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9c0b09c-51fc-477e-a0fc-a1226629a4f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>non_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ExplanationWhy the edits made under my usernam...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"MoreI can't make any real suggestions on impr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9c0b09c-51fc-477e-a0fc-a1226629a4f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9c0b09c-51fc-477e-a0fc-a1226629a4f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9c0b09c-51fc-477e-a0fc-a1226629a4f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d46ff734-dd61-4516-9d05-d5e888868e08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d46ff734-dd61-4516-9d05-d5e888868e08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d46ff734-dd61-4516-9d05-d5e888868e08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "#@title Preprocesing the dataset\n",
        "dataframe = pd.read_csv(URL_path)\n",
        "dataframe_test_import = pd.read_csv(URL_test)\n",
        "dataframe_test_labels = pd.read_csv(URL_test_labels)\n",
        "print(dataframe.head())\n",
        "\n",
        "\"\"\"\n",
        "Test dataset preparation\n",
        "\"\"\"\n",
        "attributes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "new_attributes = attributes + [\"non_toxic\"]\n",
        "\n",
        "dataframe_test_labels_filtered = dataframe_test_labels.loc[dataframe_test_labels[attributes].sum(axis=1) >= 0]\n",
        "dataframe_test_labels_filtered.shape\n",
        "dataframe_test = dataframe_test_labels_filtered.merge(dataframe_test_import, on='id')\n",
        "dataframe_test = dataframe_test.drop(columns=[\"id\"])\n",
        "\n",
        "SAMPLE_PERCENTAGE_TEST = 1 #@param\n",
        "dataframe_test=dataframe_test.sample(frac=SAMPLE_PERCENTAGE_TEST,random_state=42)\n",
        "\n",
        "print(dataframe_test.shape)\n",
        "print(\"dataframe_test\")\n",
        "print(dataframe_test.head())\n",
        "\n",
        "# Use the attributes list in the condition\n",
        "dataframe[\"non_toxic\"] = np.where(dataframe[attributes].any(axis=1), 0, 1)\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Is7RySLwAJe"
      },
      "source": [
        "Now we will split the dataset to understand whats happening"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dZzHz2IU2rMU",
        "outputId": "a0281552-335a-40cb-971a-19b0ffad49d8"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        toxic  severe_toxic  obscene  threat  insult\n",
              "0           0             0        0       0       0\n",
              "1           0             0        0       0       0\n",
              "2           0             0        0       0       0\n",
              "3           0             0        0       0       0\n",
              "4           0             0        0       0       0\n",
              "...       ...           ...      ...     ...     ...\n",
              "144785      0             0        0       0       0\n",
              "144786      0             0        0       0       0\n",
              "144787      0             0        0       0       0\n",
              "144788      0             0        0       0       0\n",
              "144789      0             0        0       0       0\n",
              "\n",
              "[144790 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1232a9b4-a1c9-45e5-b622-1ae5eae2e1e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144785</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144786</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144787</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144788</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144789</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144790 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1232a9b4-a1c9-45e5-b622-1ae5eae2e1e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1232a9b4-a1c9-45e5-b622-1ae5eae2e1e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1232a9b4-a1c9-45e5-b622-1ae5eae2e1e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-daee45c4-e59b-4474-82f1-82e1ce6adebe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-daee45c4-e59b-4474-82f1-82e1ce6adebe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-daee45c4-e59b-4474-82f1-82e1ce6adebe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi6iHiq4DtuD",
        "outputId": "b6d235c7-eee5-40c0-8c40-beab218c83e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (144790, 7)\n",
            "TRAIN Dataset: (115832, 7)\n",
            "TEST Dataset: (28958, 7)\n"
          ]
        }
      ],
      "source": [
        "#@title Split the dataset\n",
        "# drop the non toxic column\n",
        "dataframe.drop(columns= [\"non_toxic\"], inplace= True)\n",
        "\n",
        "# sample sisze\n",
        "SAMPLE_PERCENTAGE = 1 #@param\n",
        "dataframe_clean=dataframe.sample(frac=SAMPLE_PERCENTAGE,random_state=42)\n",
        "\n",
        "# split\n",
        "train_size = 0.8 #@param\n",
        "train_dataset=dataframe_clean.sample(frac=train_size,random_state=42)\n",
        "validation_dataset=dataframe_clean.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(dataframe_clean.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(validation_dataset.shape))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5ZpWl8MtOk",
        "outputId": "63f6691a-801b-4bd8-81c4-c9116640a840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples for train_dataset: (23857, 7)\n",
            "tensor([0.4361, 0.0428, 0.2414, 0.0141, 0.2248, 0.0409])\n"
          ]
        }
      ],
      "source": [
        "def reduce_size_data_train(dataset:pd.DataFrame, sample_name: str)->pd.DataFrame:\n",
        "    \"\"\" reduce the size of the dataset \"\"\"\n",
        "    target_y =dataset.iloc[:,1:].sum()\n",
        "    attributes_non_toxic = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "    non_toxic = dataset.loc[dataset[attributes_non_toxic].sum(axis=1) == 0]\n",
        "    toxic = dataset.loc[dataset[attributes_non_toxic].sum(axis=1) > 0]\n",
        "    non_toxic = non_toxic.sample(n=target_y[\"toxic\"], random_state=7)\n",
        "    dataset = pd.concat([toxic,non_toxic]).reset_index(drop=True)\n",
        "    print(f\"samples for {sample_name}: {dataset.shape}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dataset = reduce_size_data_train(train_dataset, \"train_dataset\")\n",
        "\n",
        "def normalize_values(dataset:pd.DataFrame)-> torch.tensor:\n",
        "    target_y = dataset.iloc[:,1:].sum()\n",
        "    weights_list = target_y.tolist()\n",
        "    weights = torch.tensor(weights_list, dtype=torch.float32)\n",
        "    normalized_weights = weights / weights.sum()\n",
        "    print(normalized_weights)\n",
        "\n",
        "    return normalized_weights\n",
        "\n",
        "normalized_weights = normalize_values(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsvsi4WrPRCQ"
      },
      "source": [
        "We reduced the dataset size from 100k to 26k, removing a significant number of rows. This reduction allows the model to improve both in terms of training time and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3JoEZ6WU2dD"
      },
      "source": [
        "# Create a dataset\n",
        "\n",
        "We will be preparing the dataset for the importation!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "S2rO82OqU-iT"
      },
      "outputs": [],
      "source": [
        "#@title custom dataset import class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe: pd.DataFrame, comment_str_title: str,  tokenizer, attributes, max_token_len= 128, sample= None):\n",
        "\n",
        "        assert isinstance(dataframe, pd.DataFrame), \"dataframe needs to be a pandas DataFrame for this code to work\"\n",
        "\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_token_len = max_token_len\n",
        "        self.attributes = attributes\n",
        "        self.sample = sample\n",
        "        self._prepare_data()\n",
        "\n",
        "        # column to select\n",
        "        self.comment_str_title = comment_str_title\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        \"\"\"Prepare the data and imported\"\"\"\n",
        "        # data = pd.read_csv(self.data_path)\n",
        "        data = self.dataframe.copy()\n",
        "        # add the non toxic column\n",
        "        data[\"non_toxic\"] = np.where(data[attributes].any(axis=1), 0, 1)\n",
        "        # data[\"unhealthy\"] = np.where(data[\"healthy\"] == 1, 0, 1)\n",
        "\n",
        "        # extract the sample with some attributes\n",
        "        if self.sample is not None:\n",
        "            toxic = data.loc[data[self.attributes].sum(axis=1) > 0]\n",
        "            non_toxic = data.loc[data[self.attributes].sum(axis=1) == 0]\n",
        "            # extract the sample from the healthy values\n",
        "            non_toxic = non_toxic.sample(min(self.sample, len(non_toxic)), random_state=7)\n",
        "            self.data = pd.concat([non_toxic, toxic])\n",
        "        else:\n",
        "            self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Length of the dataset\"\"\"\n",
        "        return (len(self.data))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get item from the dataset\"\"\"\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        # item as a string\n",
        "        comment = str(data_row[self.comment_str_title])\n",
        "        # attributes_numbers = torch.FloatTensor(data_row.iloc[self.attributes])\n",
        "        attributes_numbers = torch.FloatTensor(data_row[self.attributes].values.astype(float))\n",
        "\n",
        "        # extract the tokens and prepared to apply it to the comment line\n",
        "        tokens = self.tokenizer.encode_plus(\n",
        "                    comment,\n",
        "                    add_special_tokens = True,\n",
        "                    max_length = self.max_token_len,\n",
        "                    padding = 'max_length',\n",
        "                    truncation = True, # cap the comments to a max length of tokens\n",
        "                    return_tensors = 'pt', # return tensors\n",
        "                    return_attention_mask = True,\n",
        "                    return_token_type_ids = False, # this its not need it\n",
        "                    )\n",
        "\n",
        "        tokens_as_words = self.tokenizer.convert_ids_to_tokens(tokens.input_ids.flatten().tolist())\n",
        "\n",
        "        return {'input_id': tokens.input_ids.flatten(),\n",
        "                'attention_mask': tokens.attention_mask.flatten(),\n",
        "                'labels': attributes_numbers,\n",
        "                'labels_names': self.attributes,\n",
        "                'text_tokens': tokens_as_words}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqK6ioL_EAOi"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "un1XHIArVZWt"
      },
      "outputs": [],
      "source": [
        "#@title Custom class data loader\n",
        "class Data_loader_Custom(pl.LightningDataModule):\n",
        "    def __init__(self, train_dataframe, val_dataframe , attributes, comment_str_title: str, tokenizer,model_name = 'roberta-base',   batch_size= 16, max_token_len= 128 , sample= None, num_workers= 4, prediction_count = False):\n",
        "        super().__init__()\n",
        "        self.train_dataframe = train_dataframe\n",
        "        self.val_dataframe = val_dataframe\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "        self.comment_str_title = comment_str_title\n",
        "        self.attributes = attributes\n",
        "        self.sample = sample\n",
        "        self.num_workers = num_workers\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_name = model_name\n",
        "        self.prediction_count = prediction_count\n",
        "\n",
        "        # check if exist\n",
        "        self.has_train_data = train_dataframe is not None\n",
        "        self.has_val_data = val_dataframe is not None\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.has_train_data:\n",
        "            return len(self.train_dataset)\n",
        "        if self.has_val_data:\n",
        "            return len(self.validation_dataset)\n",
        "\n",
        "    def len_predictions(self):\n",
        "        if self.has_val_data:\n",
        "            return len(self.validation_dataset)\n",
        "\n",
        "    # this its using the LightningDataModule for seting up\n",
        "    def setup(self, stage= None):\n",
        "        if stage in (None, 'fit'):\n",
        "            # train set\n",
        "            self.train_dataset = CustomDataset(\n",
        "                                dataframe=  self.train_dataframe,\n",
        "                                comment_str_title =  self.comment_str_title,\n",
        "                                attributes =  self.attributes,\n",
        "                                tokenizer =  self.tokenizer,\n",
        "                                max_token_len =  self.max_token_len,\n",
        "                                sample= self.sample)\n",
        "            # validation set\n",
        "            self.validation_dataset = CustomDataset(\n",
        "                                dataframe=  self.val_dataframe,\n",
        "                                comment_str_title =  self.comment_str_title,\n",
        "                                attributes =  self.attributes,\n",
        "                                tokenizer =  self.tokenizer,\n",
        "                                max_token_len =  self.max_token_len,\n",
        "                                sample= self.sample)\n",
        "        if stage == 'predict':\n",
        "            self.predict_dataset  = CustomDataset(\n",
        "                                dataframe=  self.val_dataframe,\n",
        "                                comment_str_title =  self.comment_str_title,\n",
        "                                attributes =  self.attributes,\n",
        "                                tokenizer =  self.tokenizer,\n",
        "                                max_token_len =  self.max_token_len,\n",
        "                                sample= self.sample)\n",
        "\n",
        "    # dataload the the different sets\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=  self.num_workers, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size, num_workers= self.num_workers, shuffle=False)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.predict_dataset, batch_size=self.batch_size, num_workers= self.num_workers, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhZo2lLEExI"
      },
      "source": [
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the models"
      ],
      "metadata": {
        "id": "kp8tuTAgcCcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title preparing the architecture of the 2 models\n",
        "class Classifier_model_loader(nn.Module):\n",
        "    def __init__(self, config: dict, loss_function=None):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.pretrained_model = AutoModel.from_pretrained(config['model_name'], return_dict=True)\n",
        "        self.hidden = nn.Linear(self.pretrained_model.config.hidden_size, self.pretrained_model.config.hidden_size)\n",
        "        self.classification = nn.Linear(self.pretrained_model.config.hidden_size, self.config[\"n_labels\"])\n",
        "        self.dropout = nn.Dropout(config[\"dropout_vals\"])\n",
        "\n",
        "        # Use provided loss function, or default to BCEWithLogitsLoss\n",
        "        if loss_function is None:\n",
        "            self.loss_function = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        else:\n",
        "            self.loss_function = loss_function\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.pretrained_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_out = torch.mean(output.last_hidden_state, 1)\n",
        "        pooled_output = self.hidden(pooled_out)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        pooled_output = torch.relu(pooled_output)\n",
        "        logits = self.classification(pooled_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def compute_loss(self, predictions, targets):\n",
        "        return self.loss_function(predictions, targets)\n",
        "\n",
        "\n",
        "# Initialize the model with the same configuration\n",
        "roberta_015 = Classifier_model_loader(config_models,\n",
        "                                       loss_function=nn.BCEWithLogitsLoss(weight=normalized_weights))\n",
        "roberta_015 = roberta_015.to(device)\n",
        "roberta_015.load_state_dict(torch.load(os.path.join(URL_model_saved_015, \"model_015.pth\")))\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(\"-------------------------\")\n",
        "print(roberta_015)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPixw8PgcEXn",
        "outputId": "3224e6cb-6dff-459b-f798-e3a450aa25d0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-f1148236834d>:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  roberta_015.load_state_dict(torch.load(os.path.join(URL_model_saved_015, \"model_015.pth\")))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "-------------------------\n",
            "Classifier_model_loader(\n",
            "  (pretrained_model): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (hidden): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classification): Linear(in_features=768, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.3789390401864389, inplace=False)\n",
            "  (loss_function): BCEWithLogitsLoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpsyvuaZQuUm"
      },
      "source": [
        "# Predict the model\n",
        "We have two models, 015 and 017, where we will experiment with varying thresholds to understand how adjusting them can help filter values effectively. By setting different thresholds for each category, we aim to optimize the results and achieve better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Xt9mvXzpNA",
        "outputId": "a9cf2dcf-299c-4c06-87d6-bd2788ead3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28958, 6)\n",
            "(63978, 6)\n"
          ]
        }
      ],
      "source": [
        "#@title predictibility model\n",
        "def classify_raw_comments(model, dataset_loader_class):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    input_id_list = []\n",
        "    attention_mask_list = []\n",
        "    text_tokens_list = []\n",
        "\n",
        "    for batch in dataset_loader_class.predict_dataloader():\n",
        "        input_ids = batch['input_id'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        text_tokens = batch[\"text_tokens\"]\n",
        "        # text_tokens_list.append(text_tokens)\n",
        "        # if isinstance(text_tokens, list) and isinstance(text_tokens[0], list):\n",
        "        #     text_tokens = [token for sublist in text_tokens for token in sublist]  # Flatten the list\n",
        "        text_tokens_list.append(text_tokens)\n",
        "\n",
        "        # Make the prediction\n",
        "        with torch.no_grad():  # Disable gradient calculation for inference\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Sigmoid activation for multi-label classification\n",
        "        batch_predictions = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "        # predictions\n",
        "        all_predictions.extend(batch_predictions)\n",
        "        input_id_list.extend(input_ids)\n",
        "        attention_mask_list.extend(attention_mask)\n",
        "    # Stack all predictions into a numpy array\n",
        "    flatten_predictions = np.stack(all_predictions)\n",
        "\n",
        "    return flatten_predictions, input_id_list, attention_mask_list, text_tokens_list\n",
        "\n",
        "\"\"\"\n",
        "create data loaders\n",
        "\"\"\"\n",
        "validation_dataloader = Data_loader_Custom(\n",
        "                   train_dataframe = train_dataset,\n",
        "                   val_dataframe = validation_dataset,\n",
        "                   attributes = attributes,\n",
        "                   comment_str_title = 'comment_text',\n",
        "                   tokenizer = AutoTokenizer.from_pretrained(config_models[\"model_name\"]),\n",
        "                   batch_size= config_models[\"batch_size\"],\n",
        "                   max_token_len= 256 ,\n",
        "                   sample= None,\n",
        "                   num_workers= num_workers_colab,\n",
        "                   prediction_count= False)\n",
        "\n",
        "test_dataloader = Data_loader_Custom(\n",
        "                   train_dataframe = train_dataset,\n",
        "                   val_dataframe = dataframe_test,\n",
        "                   attributes = attributes,\n",
        "                   comment_str_title = 'comment_text',\n",
        "                   tokenizer = AutoTokenizer.from_pretrained(config_models[\"model_name\"]),\n",
        "                   batch_size= config_models[\"batch_size\"],\n",
        "                   max_token_len= 256 ,\n",
        "                   sample= None,\n",
        "                   num_workers= num_workers_colab,\n",
        "                   prediction_count= False)\n",
        "\n",
        "\n",
        "validation_dataloader.setup(stage='predict')\n",
        "predictions_object_val_15, input_val_15, attention_val_15, text_tokens_val_15 = classify_raw_comments(roberta_015, validation_dataloader)\n",
        "print(predictions_object_val_15.shape)\n",
        "\n",
        "test_dataloader.setup(stage='predict')\n",
        "predictions_object_test_15, input_test_15, attention_test_15, text_tokens_test_15 = classify_raw_comments(roberta_015, test_dataloader)\n",
        "print(predictions_object_test_15.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Review confusion matrix for the thresholds 10 ann 40%"
      ],
      "metadata": {
        "id": "BRA5UVRvSpdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_calculation(predictions_object, true_labels, class_thresholds):\n",
        "    \"\"\"\n",
        "    Compute confusion matrices per class using class-specific thresholds.\n",
        "\n",
        "    :param predictions_object: Numpy array with model predictions.\n",
        "    :param true_labels: Numpy array with ground truth labels.\n",
        "    :param class_thresholds: Dictionary with thresholds for each class.\n",
        "    \"\"\"\n",
        "    confusion_matrices = []\n",
        "    num_classes = true_labels.shape[1]  # Number of classes\n",
        "\n",
        "    # Loop through each class and apply the specific threshold\n",
        "    for i in range(num_classes):\n",
        "        attribute_name = list(class_thresholds.keys())[i]\n",
        "        threshold = class_thresholds.get(attribute_name, 0.5)  # Default to 0.5 if no threshold\n",
        "\n",
        "\n",
        "        true_class = true_labels[:, i]\n",
        "        pred_probs = predictions_object[:, i]\n",
        "        pred_class = (pred_probs >= threshold).astype(int)\n",
        "        if len(true_class) != len(pred_class):\n",
        "            raise ValueError(\"Mismatch between lengths of true labels and predictions.\")\n",
        "\n",
        "        # Compute confusion matrix for this class\n",
        "        cm = confusion_matrix(true_class, pred_class)\n",
        "        confusion_matrices.append({\n",
        "            \"class\": attribute_name,\n",
        "            \"threshold\": threshold,\n",
        "            \"confusion_matrix\": cm\n",
        "        })\n",
        "\n",
        "    # Print results\n",
        "    print(\"========================\")\n",
        "    for result in confusion_matrices:\n",
        "        print(f\"Class: {result['class']} (Threshold: {result['threshold']:.2f})\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(result[\"confusion_matrix\"])\n",
        "        print()\n",
        "    print(\"========================\")\n",
        "\n",
        "\n",
        "class_thresholds = {\n",
        "    \"toxic\": 0.50,\n",
        "    \"severe_toxic\": 0.10,\n",
        "    \"obscene\": 0.50,\n",
        "    \"threat\": 0.50,\n",
        "    \"insult\": 0.50,\n",
        "    \"identity_hate\": 0.10\n",
        "}\n",
        "\n",
        "# Example input: replace with actual data\n",
        "true_labels_val_15 = np.array(validation_dataset[attributes].values)\n",
        "threshold_calculation(predictions_object_val_15, true_labels_val_15, class_thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_tE5-LGWBls",
        "outputId": "39eb67bf-3182-445d-e038-595360b7f151"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================\n",
            "Class: toxic (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[24530  1596]\n",
            " [  211  2621]]\n",
            "\n",
            "Class: severe_toxic (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[27579  1077]\n",
            " [   11   291]]\n",
            "\n",
            "Class: obscene (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[27107   293]\n",
            " [  293  1265]]\n",
            "\n",
            "Class: threat (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[28880     0]\n",
            " [   78     0]]\n",
            "\n",
            "Class: insult (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[27079   365]\n",
            " [  422  1092]]\n",
            "\n",
            "Class: identity_hate (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[26996  1726]\n",
            " [   59   177]]\n",
            "\n",
            "========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def threshold_classification_report(predictions_object, true_labels, class_thresholds):\n",
        "    \"\"\"\n",
        "    Evaluate predictions across multiple thresholds in a classification report.\n",
        "\n",
        "    :param predictions_object: Numpy array with model predictions.\n",
        "    :param true_labels: Numpy array with ground truth labels.\n",
        "    :param class_thresholds: Dictionary with thresholds for each class.\n",
        "    \"\"\"\n",
        "    # Initialize list to store confusion matrices and reports\n",
        "    results = []\n",
        "\n",
        "    # Loop through each class-specific threshold\n",
        "    for i, class_name in enumerate(class_thresholds.keys()):\n",
        "        class_threshold = class_thresholds[class_name]\n",
        "\n",
        "        # Apply class-specific threshold to predictions for this class\n",
        "        class_predicted_labels = (predictions_object[:, i] >= class_threshold).astype(int)\n",
        "\n",
        "        # Generate confusion matrix for the current class\n",
        "        class_conf_matrix = confusion_matrix(true_labels[:, i], class_predicted_labels)\n",
        "\n",
        "        # Generate classification report for the current class\n",
        "        class_report = classification_report(\n",
        "            true_labels[:, i],\n",
        "            class_predicted_labels,\n",
        "            target_names=[f\"Not {class_name}\", class_name]\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            \"class\": class_name,\n",
        "            \"threshold\": class_threshold,\n",
        "            \"confusion_matrix\": class_conf_matrix,\n",
        "            \"classification_report\": class_report\n",
        "        })\n",
        "\n",
        "    # Print results after all computations are done\n",
        "    print(\"=\" * 50)\n",
        "    print(\"=\" * 50)\n",
        "    for result in results:\n",
        "        print(f\"Class: {result['class']} (Threshold: {result['threshold']:.2f})\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(result[\"confusion_matrix\"])\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(result[\"classification_report\"])\n",
        "        print(\"========================\")\n",
        "\n",
        "\n",
        "\n",
        "# Example input: replace with actual data\n",
        "true_labels_val_15 = np.array(validation_dataset[attributes].values)\n",
        "threshold_classification_report(predictions_object_val_15, true_labels_val_15, class_thresholds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNohYO5loWf6",
        "outputId": "b9e4d883-0f3f-42cd-e02e-e7981193e8b1"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "==================================================\n",
            "Class: toxic (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[24530  1596]\n",
            " [  211  2621]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not toxic       0.99      0.94      0.96     26126\n",
            "       toxic       0.62      0.93      0.74      2832\n",
            "\n",
            "    accuracy                           0.94     28958\n",
            "   macro avg       0.81      0.93      0.85     28958\n",
            "weighted avg       0.96      0.94      0.94     28958\n",
            "\n",
            "========================\n",
            "Class: severe_toxic (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[27579  1077]\n",
            " [   11   291]]\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Not severe_toxic       1.00      0.96      0.98     28656\n",
            "    severe_toxic       0.21      0.96      0.35       302\n",
            "\n",
            "        accuracy                           0.96     28958\n",
            "       macro avg       0.61      0.96      0.66     28958\n",
            "    weighted avg       0.99      0.96      0.97     28958\n",
            "\n",
            "========================\n",
            "Class: obscene (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[27107   293]\n",
            " [  293  1265]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not obscene       0.99      0.99      0.99     27400\n",
            "     obscene       0.81      0.81      0.81      1558\n",
            "\n",
            "    accuracy                           0.98     28958\n",
            "   macro avg       0.90      0.90      0.90     28958\n",
            "weighted avg       0.98      0.98      0.98     28958\n",
            "\n",
            "========================\n",
            "Class: threat (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[28880     0]\n",
            " [   78     0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not threat       1.00      1.00      1.00     28880\n",
            "      threat       0.00      0.00      0.00        78\n",
            "\n",
            "    accuracy                           1.00     28958\n",
            "   macro avg       0.50      0.50      0.50     28958\n",
            "weighted avg       0.99      1.00      1.00     28958\n",
            "\n",
            "========================\n",
            "Class: insult (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[27079   365]\n",
            " [  422  1092]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not insult       0.98      0.99      0.99     27444\n",
            "      insult       0.75      0.72      0.74      1514\n",
            "\n",
            "    accuracy                           0.97     28958\n",
            "   macro avg       0.87      0.85      0.86     28958\n",
            "weighted avg       0.97      0.97      0.97     28958\n",
            "\n",
            "========================\n",
            "Class: identity_hate (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[26996  1726]\n",
            " [   59   177]]\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Not identity_hate       1.00      0.94      0.97     28722\n",
            "    identity_hate       0.09      0.75      0.17       236\n",
            "\n",
            "         accuracy                           0.94     28958\n",
            "        macro avg       0.55      0.84      0.57     28958\n",
            "     weighted avg       0.99      0.94      0.96     28958\n",
            "\n",
            "========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After several tests, we have decided to stick with the following parameters for the model:**\n",
        "\n",
        "```python\n",
        "class_thresholds = {\n",
        "    \"toxic\": 0.50,\n",
        "    \"severe_toxic\": 0.10,\n",
        "    \"obscene\": 0.50,\n",
        "    \"threat\": 0.50,\n",
        "    \"insult\": 0.50,\n",
        "    \"identity_hate\": 0.10\n",
        "}\n",
        "```\n",
        "\n",
        "These thresholds seem to yield the best performance so far. To validate this, we will apply these parameters to the test dataset and evaluate if there is an improvement in the results.\n"
      ],
      "metadata": {
        "id": "sFkBJHytzzFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def all_threshold_classification_report(predictions_object, true_labels, class_thresholds):\n",
        "    \"\"\"\n",
        "    Evaluate predictions across multiple thresholds in a classification report.\n",
        "\n",
        "    :param predictions_object: Numpy array with model predictions.\n",
        "    :param true_labels: Numpy array with ground truth labels.\n",
        "    :param class_thresholds: Dictionary with thresholds for each class.\n",
        "    \"\"\"\n",
        "    # Initialize lists to store predictions and true labels for all instances\n",
        "    all_true_labels = []\n",
        "    all_predicted_labels = []\n",
        "\n",
        "    # Loop through each class-specific threshold and collect results\n",
        "    for i, class_name in enumerate(class_thresholds.keys()):\n",
        "        class_threshold = class_thresholds[class_name]\n",
        "\n",
        "        # Apply class-specific threshold to predictions for this class\n",
        "        class_predicted_labels = (predictions_object[:, i] >= class_threshold).astype(int)\n",
        "\n",
        "        # Append to the lists for overall confusion matrix and classification report\n",
        "        all_true_labels.extend(true_labels[:, i])\n",
        "        all_predicted_labels.extend(class_predicted_labels)\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    all_true_labels = np.array(all_true_labels)\n",
        "    all_predicted_labels = np.array(all_predicted_labels)\n",
        "\n",
        "    # Compute confusion matrix for the entire set of predictions\n",
        "    global_conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "\n",
        "    # Compute the classification report for the entire set of predictions\n",
        "    global_class_report = classification_report(all_true_labels, all_predicted_labels)\n",
        "\n",
        "    # Print results\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Global Confusion Matrix:\")\n",
        "    print(global_conf_matrix)\n",
        "    print(\"=\" * 50)\n",
        "    print(\"\\nGlobal Classification Report:\")\n",
        "    print(global_class_report)\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "\n",
        "# Example input: replace with actual data\n",
        "true_labels_val_15 = np.array(validation_dataset[attributes].values)\n",
        "all_threshold_classification_report(predictions_object_val_15, true_labels_val_15, class_thresholds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84uiJUMY172i",
        "outputId": "0a3cfbb9-ddd3-4302-da40-3283ef5ab4b1"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Global Confusion Matrix:\n",
            "[[162171   5057]\n",
            " [  1074   5446]]\n",
            "==================================================\n",
            "\n",
            "Global Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98    167228\n",
            "           1       0.52      0.84      0.64      6520\n",
            "\n",
            "    accuracy                           0.96    173748\n",
            "   macro avg       0.76      0.90      0.81    173748\n",
            "weighted avg       0.98      0.96      0.97    173748\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems that after the tunning of the threshold we win a 85% of the values so this its a good result overall."
      ],
      "metadata": {
        "id": "Khr3U5si4Nap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test dataset prediction"
      ],
      "metadata": {
        "id": "QkHXoNbZsWmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input: replace with actual data\n",
        "true_labels_test_15 = np.array(dataframe_test[attributes].values)\n",
        "threshold_calculation(predictions_object_test_15, true_labels_test_15, class_thresholds)"
      ],
      "metadata": {
        "id": "VYml2XmtSKHY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e713db-b785-4e2d-c8a1-a5709a5cc85a"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================\n",
            "Class: toxic (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[50786  7102]\n",
            " [  422  5668]]\n",
            "\n",
            "Class: severe_toxic (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[59726  3885]\n",
            " [   34   333]]\n",
            "\n",
            "Class: obscene (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[59029  1258]\n",
            " [ 1109  2582]]\n",
            "\n",
            "Class: threat (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[63724    43]\n",
            " [  211     0]]\n",
            "\n",
            "Class: insult (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[59665   886]\n",
            " [ 1475  1952]]\n",
            "\n",
            "Class: identity_hate (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[57153  6113]\n",
            " [  199   513]]\n",
            "\n",
            "========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_classification_report(predictions_object_test_15, true_labels_test_15, class_thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lJ2MXu31Zgs",
        "outputId": "5a14fddb-3496-464c-daa4-66cf47767855"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "==================================================\n",
            "Class: toxic (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[50786  7102]\n",
            " [  422  5668]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not toxic       0.99      0.88      0.93     57888\n",
            "       toxic       0.44      0.93      0.60      6090\n",
            "\n",
            "    accuracy                           0.88     63978\n",
            "   macro avg       0.72      0.90      0.77     63978\n",
            "weighted avg       0.94      0.88      0.90     63978\n",
            "\n",
            "========================\n",
            "Class: severe_toxic (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[59726  3885]\n",
            " [   34   333]]\n",
            "\n",
            "Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "Not severe_toxic       1.00      0.94      0.97     63611\n",
            "    severe_toxic       0.08      0.91      0.15       367\n",
            "\n",
            "        accuracy                           0.94     63978\n",
            "       macro avg       0.54      0.92      0.56     63978\n",
            "    weighted avg       0.99      0.94      0.96     63978\n",
            "\n",
            "========================\n",
            "Class: obscene (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[59029  1258]\n",
            " [ 1109  2582]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not obscene       0.98      0.98      0.98     60287\n",
            "     obscene       0.67      0.70      0.69      3691\n",
            "\n",
            "    accuracy                           0.96     63978\n",
            "   macro avg       0.83      0.84      0.83     63978\n",
            "weighted avg       0.96      0.96      0.96     63978\n",
            "\n",
            "========================\n",
            "Class: threat (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[63724    43]\n",
            " [  211     0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not threat       1.00      1.00      1.00     63767\n",
            "      threat       0.00      0.00      0.00       211\n",
            "\n",
            "    accuracy                           1.00     63978\n",
            "   macro avg       0.50      0.50      0.50     63978\n",
            "weighted avg       0.99      1.00      0.99     63978\n",
            "\n",
            "========================\n",
            "Class: insult (Threshold: 0.50)\n",
            "Confusion Matrix:\n",
            "[[59665   886]\n",
            " [ 1475  1952]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not insult       0.98      0.99      0.98     60551\n",
            "      insult       0.69      0.57      0.62      3427\n",
            "\n",
            "    accuracy                           0.96     63978\n",
            "   macro avg       0.83      0.78      0.80     63978\n",
            "weighted avg       0.96      0.96      0.96     63978\n",
            "\n",
            "========================\n",
            "Class: identity_hate (Threshold: 0.10)\n",
            "Confusion Matrix:\n",
            "[[57153  6113]\n",
            " [  199   513]]\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Not identity_hate       1.00      0.90      0.95     63266\n",
            "    identity_hate       0.08      0.72      0.14       712\n",
            "\n",
            "         accuracy                           0.90     63978\n",
            "        macro avg       0.54      0.81      0.54     63978\n",
            "     weighted avg       0.99      0.90      0.94     63978\n",
            "\n",
            "========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_threshold_classification_report(predictions_object_test_15, true_labels_test_15, class_thresholds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWJEPV5B4enS",
        "outputId": "6fcee7d4-688c-462f-a53b-b79d07cda58e"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "Global Confusion Matrix:\n",
            "[[350083  19287]\n",
            " [  3450  11048]]\n",
            "==================================================\n",
            "\n",
            "Global Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.95      0.97    369370\n",
            "           1       0.36      0.76      0.49     14498\n",
            "\n",
            "    accuracy                           0.94    383868\n",
            "   macro avg       0.68      0.85      0.73    383868\n",
            "weighted avg       0.97      0.94      0.95    383868\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that the model's performance has improved compared to previous runs. We've achieved a 15% increase in recall, which is the metric we prioritized for evaluation. Additionally, we are still exceeding expectations in terms of accuracy.\n"
      ],
      "metadata": {
        "id": "MGPHkQFA4rNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "df = dataframe.iloc[:,1:-1]\n",
        "columns = df.columns\n",
        "combinations = list(itertools.combinations(columns, 2))\n",
        "combination_counts = []\n",
        "for combo in combinations:\n",
        "    combo_df = df[list(combo)]\n",
        "    combo_count = combo_df.value_counts().reset_index(name='count')\n",
        "    for _, row in combo_count.iterrows():\n",
        "        combination_counts.append({\n",
        "            \"combination\": combo,\n",
        "            \"values\": row[list(combo)].to_list(),\n",
        "            \"count\": row[\"count\"]\n",
        "        })\n",
        "\n",
        "combination_counts_df = pd.DataFrame(combination_counts)\n",
        "print(combination_counts_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBoBpAKJ3HqC",
        "outputId": "e65432b0-3f07-4f09-ef08-eabfa09e37f8"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                combination  values   count\n",
            "0     (toxic, severe_toxic)  [0, 0]  130364\n",
            "1     (toxic, severe_toxic)  [1, 0]   12987\n",
            "2     (toxic, severe_toxic)  [1, 1]    1439\n",
            "3          (toxic, obscene)  [0, 0]  129907\n",
            "4          (toxic, obscene)  [1, 1]    7519\n",
            "5          (toxic, obscene)  [1, 0]    6907\n",
            "6          (toxic, obscene)  [0, 1]     457\n",
            "7           (toxic, threat)  [0, 0]  130337\n",
            "8           (toxic, threat)  [1, 0]   13999\n",
            "9           (toxic, threat)  [1, 1]     427\n",
            "10          (toxic, threat)  [0, 1]      27\n",
            "11          (toxic, insult)  [0, 0]  129870\n",
            "12          (toxic, insult)  [1, 0]    7430\n",
            "13          (toxic, insult)  [1, 1]    6996\n",
            "14          (toxic, insult)  [0, 1]     494\n",
            "15  (severe_toxic, obscene)  [0, 0]  136755\n",
            "16  (severe_toxic, obscene)  [0, 1]    6596\n",
            "17  (severe_toxic, obscene)  [1, 1]    1380\n",
            "18  (severe_toxic, obscene)  [1, 0]      59\n",
            "19   (severe_toxic, threat)  [0, 0]  142998\n",
            "20   (severe_toxic, threat)  [1, 0]    1338\n",
            "21   (severe_toxic, threat)  [0, 1]     353\n",
            "22   (severe_toxic, threat)  [1, 1]     101\n",
            "23   (severe_toxic, insult)  [0, 0]  137113\n",
            "24   (severe_toxic, insult)  [0, 1]    6238\n",
            "25   (severe_toxic, insult)  [1, 1]    1252\n",
            "26   (severe_toxic, insult)  [1, 0]     187\n",
            "27        (obscene, threat)  [0, 0]  136643\n",
            "28        (obscene, threat)  [1, 0]    7693\n",
            "29        (obscene, threat)  [1, 1]     283\n",
            "30        (obscene, threat)  [0, 1]     171\n",
            "31        (obscene, insult)  [0, 0]  135165\n",
            "32        (obscene, insult)  [1, 1]    5841\n",
            "33        (obscene, insult)  [1, 0]    2135\n",
            "34        (obscene, insult)  [0, 1]    1649\n",
            "35         (threat, insult)  [0, 0]  137136\n",
            "36         (threat, insult)  [0, 1]    7200\n",
            "37         (threat, insult)  [1, 1]     290\n",
            "38         (threat, insult)  [1, 0]     164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It also seems that some categories may not be predictably classified, as they are not connected in any way."
      ],
      "metadata": {
        "id": "3O_kZaKb5CHx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izMrFjkoKCLc"
      },
      "source": [
        "# Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning the thresholds has provided a slight improvement in the model, helping us understand that adjusting them can lead to better performance across different categories. For now, we will stick with this approach."
      ],
      "metadata": {
        "id": "znzV_ii45qae"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}